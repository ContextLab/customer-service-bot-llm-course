{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextLab/customer-service-bot-llm-course/blob/main/Assignment4_Customer_Service_Chatbot.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Context-Aware Customer Service Chatbot\n",
    "\n",
    "**PSYC 51.17: Models of Language and Communication**\n",
    "\n",
    "**Due Date: February 6, 2026 at 11:59 PM EST**\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will build a sophisticated, context-aware customer service chatbot using modern transformer models and retrieval-augmented generation (RAG) techniques.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Apply transformer-based models (BERT, Sentence-BERT) for semantic understanding\n",
    "- Implement efficient semantic search using FAISS\n",
    "- Build a complete RAG pipeline\n",
    "- Handle multi-turn conversations with context maintenance\n",
    "- Compare semantic search vs. keyword-matching baselines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Installation](#1-setup-and-installation)\n",
    "2. [Load Dataset](#2-load-dataset)\n",
    "3. [Semantic Search System](#3-semantic-search-system)\n",
    "4. [Baseline Implementation](#4-baseline-implementation)\n",
    "5. [Response Generation](#5-response-generation)\n",
    "6. [Multi-Turn Handling](#6-multi-turn-handling)\n",
    "7. [Evaluation](#7-evaluation)\n",
    "8. [Examples](#8-examples)\n",
    "9. [Conclusion](#9-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers sentence-transformers torch\n",
    "!pip install -q faiss-cpu  # Use faiss-gpu if you have GPU support\n",
    "!pip install -q datasets rank-bm25\n",
    "!pip install -q scikit-learn pandas numpy\n",
    "!pip install -q matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Choose one of the following options:\n",
    "- Option 1: HuggingFace Dataset (Recommended)\n",
    "- Option 2: Create your own knowledge base\n",
    "- Option 3: Web scraping (with compliance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load from HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Choose one of these datasets:\n",
    "# dataset = load_dataset(\"banking77\")  # Banking customer service intents\n",
    "# dataset = load_dataset(\"SetFit/customer_support\")  # Multi-domain support\n",
    "\n",
    "# Example with banking77\n",
    "print(\"Loading banking77 dataset...\")\n",
    "dataset = load_dataset(\"banking77\")\n",
    "print(f\"Dataset loaded: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Create your own knowledge base (if not using HuggingFace)\n",
    "# Uncomment and modify this if you want to create a custom knowledge base\n",
    "\n",
    "# knowledge_base = [\n",
    "#     {\n",
    "#         \"question\": \"How do I reset my password?\",\n",
    "#         \"answer\": \"To reset your password, click 'Forgot Password' on the login page...\",\n",
    "#         \"category\": \"account_access\"\n",
    "#     },\n",
    "#     # Add 100+ entries\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "print(\"Dataset structure:\")\n",
    "print(f\"Splits: {dataset.keys()}\")\n",
    "print(f\"\\nTrain examples: {len(dataset['train'])}\")\n",
    "print(f\"Test examples: {len(dataset['test'])}\")\n",
    "print(f\"\\nExample entry:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Search System\n",
    "\n",
    "Implement the semantic search system using Sentence Transformers and FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load sentence transformer model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Choose a model:\n",
    "# - 'all-MiniLM-L6-v2' (fast, good quality)\n",
    "# - 'all-mpnet-base-v2' (higher quality)\n",
    "# - 'BAAI/bge-small-en-v1.5' (state-of-the-art)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encode knowledge base\n",
    "# Your implementation here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build FAISS index\n",
    "import faiss\n",
    "\n",
    "# Your implementation here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement search function\n",
    "def semantic_search(query, k=5):\n",
    "    \"\"\"Search for the top-k most similar entries in the knowledge base.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Implementation\n",
    "\n",
    "Implement TF-IDF or BM25 baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement TF-IDF baseline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Your implementation here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement keyword search function\n",
    "def keyword_search(query, k=5):\n",
    "    \"\"\"Baseline keyword-matching search.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Response Generation\n",
    "\n",
    "Generate contextual responses based on retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement response generation (template-based or LLM-based)\n",
    "def generate_response(query, retrieved_contexts):\n",
    "    \"\"\"Generate a response based on retrieved context.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Turn Handling\n",
    "\n",
    "Implement conversation state management for multi-turn dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement conversation state management\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "        \n",
    "    def add_turn(self, user_input, bot_response):\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def get_context(self):\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def process_query(self, query):\n",
    "        # Your implementation here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "Implement comprehensive evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement retrieval metrics (Precision@k, Recall@k, MRR)\n",
    "def evaluate_retrieval(predictions, ground_truth, k=5):\n",
    "    \"\"\"Evaluate retrieval quality.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare semantic search vs. baseline\n",
    "# Your comparison here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Examples\n",
    "\n",
    "Demonstrate the system with at least 10 diverse examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Interactive demo\n",
    "example_queries = [\n",
    "    \"I can't log into my account\",\n",
    "    \"What is your return policy?\",\n",
    "    \"How do I change my shipping address?\",\n",
    "    # Add more examples...\n",
    "]\n",
    "\n",
    "for query in example_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    # Your response generation here\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Multi-turn conversation demo\n",
    "print(\"Multi-turn Conversation Demo\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Your multi-turn demo here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "*Summarize your findings, discuss limitations, and suggest improvements.*\n",
    "\n",
    "TODO: Your conclusion here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}